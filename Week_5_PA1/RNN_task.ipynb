{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN-task.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "X5yc7OL8whUy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "metadata": {
        "id": "Pk85UIeVwmJp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "679622ee-fad9-4234-8890-f50b274f71e5"
      },
      "cell_type": "code",
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "# setup_google_colab.setup_week1()\n",
        "# setup_google_colab.setup_week2()\n",
        "# setup_google_colab.setup_week3()\n",
        "# setup_google_colab.setup_week4()\n",
        "setup_google_colab.setup_week5()\n",
        "# setup_google_colab.setup_week6()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shred: setup_google_colab.py: failed to open for writing: No such file or directory\n",
            "--2018-12-01 12:33:56--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3595 (3.5K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   3.51K  --.-KB/s    in 0s      \n",
            "\n",
            "2018-12-01 12:33:56 (48.8 MB/s) - ‘setup_google_colab.py’ saved [3595/3595]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "v8LojXviwhU4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1b477dca-9007-438a-acfa-dd9539834356"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "onBJZ_AgwhVB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "mRFhlTSkwhVD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "eLhNzIa7whVJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "6712684f-9f24-4939-beec-8c689a55d55c"
      },
      "cell_type": "code",
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "O7jV_ctCwhVM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "d0275ef7-0770-4276-a694-86dc30a8652e"
      },
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEHCAYAAACgHI2PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f4931a421d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "fVRpNYPiwhVQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "VnHuN41qwhVR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75821043-7ab2-466d-e93d-2778a2dc5208"
      },
      "cell_type": "code",
      "source": [
        "tokens = set(''.join(names[:]))###all unique characters go here, padding included!\n",
        "\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A_5SBoSYwhVU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "r02fCdA9whVV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "token_to_id = {}### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "\n",
        "for i in range(n_tokens):\n",
        "    token_to_id[tokens[i]] = i\n",
        "    \n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "ijcxGQkQwhVb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_matrix(names, max_len=None, pad=0, dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "RMflaOfHwhVj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "7debbfbd-3c15-4bbd-d0a3-1b86c54ab3ed"
      },
      "cell_type": "code",
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[11  2 45 22 48 22 36 16  0]\n",
            " [11 13 16 52 53 32  0  0  0]\n",
            " [11 10 53 23 15 15 23 36  0]\n",
            " [11 13 23 52 51 22 49 49 36]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wYWhDQZAwhVu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "vYF3DlXXwhVw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "WtMvEXNSwhV0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation='relu')### YOUR CODE HERE\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens, activation='softmax')### YOUR CODE HERE "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uk7hgvMDwhV4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "SeF2rufCwhV4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = tf.concat([x_t_emb, h_t], 1)### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h)### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next)### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C9Pav3_2whV7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "KFUbjXnHwhV8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7Zyl-Gu2whV_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "B1GqYlVGwhWA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W3jlzQ_YwhWI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "JKLW3zykwhWI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "98fcd8de-25be-46eb-bd8e-57d937d84f74"
      },
      "cell_type": "code",
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "from keras.objectives import categorical_crossentropy\n",
        "loss = tf.reduce_mean(categorical_crossentropy(answers_matrix, predictions_matrix))### YOUR CODE HERE\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2745: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qJ_ogJs5whWM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: training"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "VZkaLDhBwhWN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "00fcea99-508e-490c-e6f5-d62e4ee992d2"
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzT5PtNZAAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f492ad05240>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "pXcgEKvwwhWZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "_6OrkoVHwhWb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "qCjQKI2wwhWg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "xAqJfPPBwhWk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "fe685eaf-e189-49ec-ec10-0e4adcd69bb8"
      },
      "cell_type": "code",
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Masryuuuuuuuuuu\n",
            " Marrenuuuuuuuuu\n",
            " plibimyuuuuuuuu\n",
            " Phmittauuuuuuuu\n",
            " Kerdeiuuuuuuuuu\n",
            " Ruevauuuuuuuuuu\n",
            " Carbeeuuuuuuuuu\n",
            " Oreyduuuuuuuuuu\n",
            " Bocedeuuuuuuuuu\n",
            " Donuuuuuuuuuuuu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "saoirJ4GwhWn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "1373c4be-e060-4066-e031-743949a649df"
      },
      "cell_type": "code",
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trumpeuuuuuuuuu\n",
            " Trumpeuuuuuuuuu\n",
            " Trumphanuuuuuuu\n",
            " Trumpyuuuuuuuuu\n",
            " Trumpauuuuuuuuu\n",
            " Trumpeuuuuuuuuu\n",
            " Trumphuuuuuuuuu\n",
            " Trumpauuuuuuuuu\n",
            " Trumpayuuuuuuuu\n",
            " Trumpauuuuuuuuu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IDlKuI6twhWr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "LnAhbx7jwhWv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"7quxVn5tdizlIXFP\"\n",
        "COURSERA_EMAIL = \"kmr2907akash@gmail.com\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "LiMKkHODwhW0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a0aabf73-4877-4031-c206-368d348e1837"
      },
      "cell_type": "code",
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VIdLHFhGwhW3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "MDQiuXJVwhW4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "sUXqO_3UwhW5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "059d086c-b8c4-4a1a-9976-4cd4ca9df0c2"
      },
      "cell_type": "code",
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-33-5f3812e903bf>:13: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
            "LSTM outputs for each step [batch,time,n_tokens]:\n",
            "(10, 50, 55)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "obLvSXwGwhW9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "EnHLDx4rwhW-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0225881b-e826-4009-dae1-5a9e4dc796fd"
      },
      "cell_type": "code",
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tConv1DLSTMCell\tConv2DLSTMCell\tConv3DLSTMCell\tConvLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIndRNNCell\tIndyGRUCell\tIndyLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tLayerRNNCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tSRUCell\tTimeFreqLSTMCell\tUGRNNCell\t"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "vXOYsqenwhXC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e3a2b96d-fe7a-4667-ff0b-09b5885f861f"
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTM hidden state for each step [batch,time,rnn_num_units]:\n",
            "(10, 50, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YkXywn6qz_-M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}